% Uncomment each lecture below to get that lecture.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{beamer}
% \documentclass[handout]{beamer}

%\documentclass{article}
%\usepackage{beamerarticle}

\newif\ifincludepdfcdfmapping
\includepdfcdfmappingfalse

%%%%%%
\newif\ifFIG
%\FIGfalse
\FIGtrue
%%%%%%%

\newif\ifSKIP
\SKIPfalse
\SKIPtrue

\newif\ifLecone
\Leconetrue
%\Leconefalse

\newif\ifLectwo
% \Lectwotrue
\Lectwofalse

\newif\ifLecthree
%\Lecthreetrue
\Lecthreefalse

\newif\ifLecfour
\Lecfourtrue
\Lecfourfalse

\newif\ifLecfive
\Lecfivetrue
\Lecfivefalse

\newif\ifLecsix
\Lecsixtrue
%\Lecsixfalse

\newif\ifLecseven
\Lecseventrue
\Lecsevenfalse

\newif\ifEXCLUDE
\EXCLUDEfalse
%\EXCLUDEtrue % include ALL
%%%%%%
\newif\ifFIG
% \FIGfalse
\FIGtrue
%%%%%%

%%%%%%%%%%%%%

\newif\ifcolourinformation
\colourinformationtrue

\newif\ifSHOWEDITS
\SHOWEDITSfalse
%\SHOWEDITStrue
\newif\ifSHOWEDITP
\SHOWEDITPfalse

\newif\ifSHOWDELETES
\SHOWDELETESfalse

\newif\ifSHOWDELETEP
\SHOWDELETEPfalse

\newif\ifSHOWJVSDELETES
\SHOWJVSDELETESfalse

\newif\ifSHOWJVSEDITS
\SHOWJVSEDITSfalse

\newif\ifSHOWQUERIES
\SHOWQUERIESfalse

\newif\ifCOMMENTS
\COMMENTSfalse

\newif\ifSHOWNOTES
\SHOWNOTESfalse

\newif\ifSHOWPVALUES
\SHOWPVALUESfalse

\ifSHOWEDITS
\newcommand{\edit}[1]{{\color{red}#1}}
\else
\newcommand{\edit}[1]{{#1}}
\fi

\ifSHOWEDITP
\newcommand{\editp}[1]{{\color{blue}#1}}
\else
\newcommand{\editp}[1]{{#1}}
\fi

\ifSHOWDELETES
\usepackage{soul}
\newcommand{\delete}[1]{{\color{red}\st{#1}}}
\else
\newcommand{\delete}[1]{\unskip}
\fi

\ifSHOWDELETEP
\usepackage{soul}
\newcommand{\deletep}[1]{{\color{blue}\st{#1}}}
\else
\newcommand{\deletep}[1]{\unskip}
\fi

\ifSHOWQUERIES
\newcommand{\CO}[1]{{\color{red}[CO: #1]}}
\newcommand{\query}[1]{{\color{blue}[CO: #1]}}
\else
\newcommand{\CO}[1]{\unskip}
\newcommand{\query}[1]{\unskip}
\fi

\newcommand{\graphwidth}{0.5 \textwidth}



%%%%%%%%%%%%%%%%

\newcommand{\whiteframe}{\setbeamercolor{normal text}{bg=white}}
\newcommand{\baseframecolour}{\setbeamercolor{normal text}{bg=yellow!10}}

% \setbeamertemplate{footline}[frame number] 

\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{caption}[numbered]

\mode<presentation>
{
 \usetheme{Madrid} % Madrid=JVS default, Rochester Singapore Warsaw
%  \usecolortheme{default}
  % or ...
%  \usetheme{Antibes}
%  \usetheme{Bergen}
%  \usetheme{Berkeley}
%  \usetheme{Berlin}
% \usetheme{Boadilla}
%  \usetheme{Copenhagen}
%  \usetheme{Darmstadt}
% \usetheme{default}
%  \usetheme{Dresden}
%  \usetheme{Frankfurt}
%  \usetheme{Goettingen}
%  \usetheme{Hannover}
%  \usetheme{Ilmenau}
%  \usetheme{JuanLesPins}
%  \usetheme{Luebeck}
%  \usetheme{Madrid}
%  \usetheme{Malmoe}
%  \usetheme{Marburg}
%  \usetheme{Montpellier}
%  \usetheme{PaloAlto}
%  \usetheme{Pittsburgh}
%  \usetheme{Rochester}
%  \usetheme{Singapore}
%  \usetheme{Szeged}
% \usetheme{Warsaw}

  % \setbeamercovered{transparent}
  % or whatever (possibly just delete it)
  \baseframecolour
  %\usefonttheme[onlysmall]{structurebold}
  %\setbeameroption{show only notes}
  \setbeamertemplate{footline}[frame number] % removes all but frame/tot slot.
}

%%%%% for handouts %%%
\mode<handout>
{
\usecolortheme{seagull}
\usepackage{pgfpages}
\pgfpagesuselayout{2 on 1}[a4paper,border shrink=5mm]
}

% to use https://github.com/mpflanzer/splitshow/tree/master/doc/demo
\usepackage{pgfpages}
%\setbeameroption{show notes on second screen}
% to turn splitshow  off comment out next line: \setbeameroption{show notes on second screen=right}
%\setbeameroption{show notes on second screen=right}

\usepackage{amsfonts}
%\usepackage{latexsym}
\usepackage{setspace}
\usepackage{graphicx} % article doesn't like graphics 
\usepackage{xmpmulti}
\usepackage[english]{babel}
%\usepackage{subfigure}
\usepackage{subfig} % newer than subfigure!

%\usepackage{subfig} % nbg in beamer

% \usepackage{wrapfig}
% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
%\AtBeginSubsection[]
%{
%  \begin{frame}<beamer>
%    \frametitle{Outline}
%    \tableofcontents[currentsection,currentsubsection]
%  \end{frame}
%}
%\AtBeginSection[]
%{
%  \begin{frame}<beamer>
%    \frametitle{Outline}
%    \tableofcontents[currentsection,currentsubsection]
%  \end{frame}
% }

\usepackage{tikz}
\tikzstyle{every picture}+=[font=\sffamily] % sets font to be like helv
\usetikzlibrary{decorations.pathmorphing} 
\usetikzlibrary{shapes.geometric,calc}
\usetikzlibrary{shapes,arrows}
\usepackage{lipsum}

\tikzset{
    %Define standard arrow tip
    >=stealth'
	}
\usetikzlibrary{decorations.pathmorphing} 
\usetikzlibrary{shapes.geometric,calc}
\usetikzlibrary{shapes,arrows}
\tikzstyle{int}=[draw, minimum size=2em]
\tikzstyle{init} = [pin edge={to-,thick,black}]
\usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,positioning,fit,petri}


\newlength{\RoundedBoxWidth}
\newsavebox{\GrayRoundedBox}
\newenvironment{KeyPointBox}[1][\dimexpr\textwidth-4.5ex]%
   {\setlength{\RoundedBoxWidth}{\dimexpr#1}
    \begin{lrbox}{\GrayRoundedBox}
       \begin{minipage}{\RoundedBoxWidth}}%
   {   \end{minipage}
    \end{lrbox}
    \begin{center}
    \begin{tikzpicture}%
       \draw node[draw=black,fill=black!5,rounded corners,%
             inner sep=2ex,text width=\RoundedBoxWidth]%
             {\usebox{\GrayRoundedBox}};
    \end{tikzpicture}
    \end{center}}
    
\usepackage{amssymb,amsmath}

\resetcounteronoverlays{equation}
%%%%%%%%%%%%%%%%%%% end preamble %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% PEJ's Definitions
\newcommand{\bB}{{\mathbf B}}
\newcommand{\bZ}{{\mathbf Z}}
\newcommand{\bT}{{\mathbf T}}
\newcommand{\bwtilde}{\tilde{{\mathbf w}}}
\newcommand{\ba}{{\mathbf a}}
\newcommand{\bd}{{\mathbf d}}
\newcommand{\bX}{{\mathbf X}}
\newcommand{\bI}{{\mathbf I}}
\newcommand{\bbR}{{\mathbb R}}
\newcommand{\bU}{{\mathbf U}}
% \bu redefined by PEJ 19/4/05
\newcommand{\bu}{{\mathbf u}}
\newcommand{\bV}{{\mathbf V}}
\newcommand{\bv}{{\mathbf v}}
\newcommand{\tr}{\mathrm{tr}}
\newcommand{\var}{\mathrm{var}}
\newcommand{\bPi}{\mbox{\boldmath $\Pi$}}
\newcommand{\bSigma}{\mbox{\boldmath $\Sigma$}}
\newcommand{\uu}       {{\mathbf w_1}}
\newcommand{\uuprime}       {{\mathbf w_2}}

% LATEX MATH DEFINITIONS.
\newcommand{\dalpha}{\:\:\: d \alpha}
\newcommand{\dbeta}{\:\:\: d \beta}
\newcommand{\dgamma}{\:\:\: d \gamma}
\newcommand{\dtheta}{\:\:\: d \theta}

\newcommand{\p}{p}
\newcommand{\q}{q}
\newcommand{\dd}{\delta}
\newcommand{\dpre}{E_{pre}}
\newcommand{\dpost}{E_{post}}
\newcommand{\e}{E}

\newcommand{\pext}{\rho}
\newcommand{\exppinit}{\langle p_{init} \rangle}
\newcommand{\exppext}{\langle \rho \rangle}
\newcommand{\expdelta}{\langle \delta \rangle}
\newcommand{\expdeltaalpha}{\langle \delta(\alpha) \rangle}
\newcommand{\exprho}{\langle \rho \rangle}
\newcommand{\gt}{>}
\newcommand{\lt}{<}

\newcommand{\bg}{       {\bf v      } }
% \newcommand{\bv}{       {\bf v      } }
\newcommand{\bxtilde}	{ \tilde{\bf x}}
\newcommand{\bw}{       {\bf w      } }
\newcommand{\bx}{       {\bf x      } }
\newcommand{\bsigma}{       {\bf \sigma      } }
\newcommand{\bm}{       {\bf m      } }
\newcommand{\bn}{       {\bf n      } }
\newcommand{\by}{       {\bf y      } }
\newcommand{\bz}{       {\bf z      } }
\newcommand{\bY}{       {\bf Y      } }
\newcommand{\bs}{       {\bf s      } }
\newcommand{\bA}{       {\bf A      } }
\newcommand{\bW}        {\bf W}
\newcommand{\bt}{       {\bf t	}	}

\newcommand{\tX}        {\tilde{X}}
\newcommand{\tU}        {\tilde{U}}
\newcommand{\tV}        {\tilde{V}}
\newcommand{\SP}        {\:}
\newcommand{\be}        { \begin{equation}  }
\newcommand{\ee}        { \end{equation}	}
\newcommand{\bea}       { \begin{eqnarray}  }
\newcommand{\eea}       { \end{eqnarray}    }

\renewcommand{\@}{\mbox{$\partial$}}

\newcommand{\Ch}{\hat{C}}
\newcommand{\Wh}{\hat{W}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\bxh}{\hat{\bx}}
\newcommand{\bxi}{\bx^{(i)}}

\newcommand{\jlog}	{\log}
\newcommand{\nn}	{\nonumber}

%\renewcommand{\rm} {{\overline{r}}}
\renewcommand{\Im} {{\overline{I}}}

\newcommand{\ed}	{\end{document}}

\newcommand{\jem}	{\bf}

\newcommand{\C}{R_{max}} % max coding capacity of neuron

\newcommand{\R}{Q} 
\newcommand{\bR}{{\bf R}} 

\newcommand{\jsets}{A_s}
\newcommand{\jsetx}{A_x}
\newcommand{\jsety}{A_y}

\newcommand{\nphotoreceptors}{n}

\newcommand{\npix}{n} % number of pixels in image
\newcommand{\nw}{m} % number of weights in filter

\newcommand{\gc}{y} % ganglion cell

\renewcommand{\r}{y} % LMC response 


\newcommand{\nt}{T} % total number of time steps

\newcommand{\TIMEREVERSED}{time-reversed }

\newcommand{\cov}{{\rm cov}}

\newcommand{\cop} {x} % cone output

\newcommand{\gcip} {z} % GC input

\newcommand{\A} {A} % cov matrix of inputs to GCs.

\newcommand{\bit}{\:{\rm bit}}

\newcommand{\bits}{\:{\rm bits}}

\newcommand{\bitssec}{\:{\rm bits/s}}
\newcommand{\bitss}{\:{\rm bits/s}}

\newcommand{\xhat}{\hat{x}}
\newcommand{\yhat}{\hat{y}}

\newcommand{\xt}{x_{t}}
\newcommand{\xh}{x_{h}}
\newcommand{\noiseRV} { {\rm \scalebox{\etascale} {\ensuremath{\eta}}  }    }

\newcommand{\h}{h}

\newcommand{\X}{x}
\newcommand{\Y}{y}
\renewcommand{\S}{s}

\newcommand{\rvs}{x}
\newcommand{\rvr}{y}

\newcommand{\s}{      {x     } }


\newcommand{\ie}{{i.e.\:}}
\newcommand{\eg}{{e.g.\:}}

\newcommand{\transpose}{\intercal}

\newcommand{\blambda}{\boldsymbol{\lambda}}

\newcommand{\lat}{\lambda}
\newcommand{\blat}{\blambda}

\newcommand{\Sigmapost}{\Sigma}

\newcommand{\ipunitstate}{x} % state of an input unit in bp chapter

\newcommand{\ipstate}{{x}}
\newcommand{\bipstate}{{\bx}}

\newcommand{\opstate}{{y}}
\newcommand{\bopstate}{{\by}}

\newcommand{\hop}{z}
\newcommand{\hstate}{\hop}
\newcommand{\bhstate}{{\bf \hop}}

\newcommand{\hstateouter}{z^{b}}
\newcommand{\hstateinner}{z^{a}}

\newcommand{\Rspace}{\mathbb{R}}

\newcommand{\RR}{R}

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcounter{jcounter}\setcounter{jcounter}{-1}\addtocounter{jcounter}{1} % for subsections

% Figures path: use as in: \includegraphics[width=\textwidth]{\figurepath/figLaughlin1}
\newcommand{\figurepath}{/Users/JimStone/Documents/BOOKS/book_AIEngines2019/FiguresALL}
%\newcommand{\figurepath}{Figures}
%/Users/JimStone/Documents/BOOKS/BookCompNeuro/BookEyesFliesInformationTheory/Figures

\newcommand{\figlen}{2.5in}

\newcommand{\jcorrection}[1]{{ \color{red} {\em correction:}} {\color{red}#1} }

%%%%%%%%%%%%%%%%%%%  titles

\title[{\em PSY6308}: Information Theory] 
%{Maximising Information Throughput in Single Neurons}
{Neural Information Theory}

\subtitle{Lecture 1: Laughlin's Fly} % (optional)

%\author{Jim Stone}
%\institute{CCN MSc}% Cognitive and Computational Neuroscience}
%\institute{Msc in Cognitive and Computational Neuroscience \\Department of Psychology}

\date{}
%[2008] % (optional){2008}

\subject{Computational Neuroscience 2}
% This is only inserted into the PDF information catalog. Can be left
% out.

% The logo
% \pgfdeclareimage[height=1cm]{reverb-logo}{../reverb_logo}
% \logo{\pgfuseimage{reverb-logo}}

%\AtBeginSection[]
%{
%  \begin{frame}
%    \frametitle{Table of Contents}
%    \tableofcontents[currentsection,currentsubsection]
%  \end{frame}
%}

\newcommand{\joutput}{state }
\newcommand{\joutputs}{states }

\newcommand{\unitinput}{u}

\newcommand{\yip}{\breve{y}}
\renewcommand{\yip}{v}
\renewcommand{\yip}{\unitinput}

\newcommand{\yop}{y}



\newcommand{\biasstate}{x_{bias}}
\newcommand{\hip}{\breve{y}}
\renewcommand{\hip}{\unitinput}
\renewcommand{\hop}{{y}}

\newcommand{\gip}{\breve{g}}
\newcommand{\xip}{\breve{x}}

\renewcommand{\xip}{\unitinput}

%\newcommand{\ytarg}{{\rm y}}
\newcommand{\bytarg}{{\tt {\bf Y}}}
\renewcommand{\bytarg}{\mathsf{\bf Y}} % never used!
\renewcommand{\by}{{\bf y}}

\newcommand{\ytarg} {{\tt Y}}
\renewcommand{\ytarg} {\mathsf{y}}

% The font-selection commands of LaTeX 2.09 were \rm, \sf, \tt, \it, \sl, \em and \bf; they were modal commands, so you used them as:

\newcommand{\ymodel}{y}

%\newcommand{\ytarg}{y_{target}}
\newcommand{\wrand}{w_{\rm rand}}

\newcommand{\xneuron}{{\rm x}}
\newcommand{\xmodel}{x}

\newcommand{\jequals}{\:\:\: = \:\:\:}

\newcommand{\g}{f} % activation function
\newcommand{\F}{F} % network function

\usepackage{algorithm2e}

\newenvironment{BoxExplainer}[1][\dimexpr\textwidth]%
   {\setlength{\RoundedBoxWidth}{4in}%{\dimexpr#1}
    \begin{lrbox}{\GrayRoundedBox}
       \begin{minipage}{\RoundedBoxWidth}}%
   {   \end{minipage}
    \end{lrbox}
    \begin{center}
    \begin{tikzpicture}%
       \draw node[draw=black,fill=black!5,rounded corners,%
             inner sep=2ex,text width=\RoundedBoxWidth]%
             {\usebox{\GrayRoundedBox}};
    \end{tikzpicture}
    \end{center}}
    
    \newcommand{\Lrate}{\epsilon}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%% end title
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% - ONLY CURRENT
%\includeonlyframes{currentframe, currentframe0}
%%%%%%%%%%%%
%%%%%%%%%%%%
%%%%%%%%%%%%
\newcounter{lecnum}


\section{LECTURE 1} % 1

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\setcounter{lecnum}{2}
\title{%Lecture \thelecnum\\
Backprop\\How it works (and how it fails)}
\subtitle{} % (optional)
\setcounter{framenumber}{0}
\begin{frame}
  \maketitle % article likes titlepage
   % \center{MSc in Cognitive and Computational Neuroscience  }
   %Things to do: Add movies of training etc + movies of GAN/VAE/Pole balancing/RL demos.
  \center{James V Stone}
    \center{Sheffield University}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subtitle{Lecture \thelecnum: Information: What is it, and why does it matter?} % (optional)
\begin{frame}
  \frametitle{Structure}
  %\vspace{-1in}
 \begin{description}
\item[ ] What's the problem?
\item[] A deep neural network: Credit assignment
\item[] The simplest neural network
 \begin{description}
 	\item[] Gradient descent: The delta term
	\item[] Gradient descent with two input units
\end{description}
\item[] The Backprop Algorithm 
\item[] Local minima
\item[] Overfitting and generalisation
%\item[] Bulldozing backprop (Schmidhuber)
\end{description}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{A Deep Neural Network: Credit Assignment}
\begin{figure}[b!] 
\begin{center}
\def\layersep{2.0cm}
\def\vertsepfactor{0.8}
\def\nip{5}
\def\nhid{\nip}
\def\nop{3}
\begin{tikzpicture}[shorten >=1pt,->,draw=black!100, node distance=\layersep, thin]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]

    	\tikzstyle{neuron}=[circle,fill=black!25,minimum size=20pt,inner sep=0pt,ball color=gray!20]
    	\tikzstyle{input neuron}=[neuron, fill= black!50];
    	\tikzstyle{output neuron}=[neuron, fill=black!50];
    	\tikzstyle{hidden neuron}=[neuron, fill= black!50];
 	\tikzstyle{hidden2 neuron}=[neuron, fill= black!50];
        \tikzstyle{hidden3 neuron}=[neuron, fill= black!50];

    	\tikzstyle{annot} = [text width=4em, text centered]

  % Draw the input layer nodes
    \foreach \name / \y in {1,...,\nip}
  % This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
      %\node[input neuron, pin=left:Input \#\y] (I-\name) at (0,-\y) {};
      % Skip labels
        \node[input neuron] (I-\name) at (0,-\y* \vertsepfactor) {};
      % add labels

  % Draw the hidden layer nodes
    \foreach \name / \y in {1,...,\nhid}
        \path[yshift=0.0cm]
            node[hidden neuron] (H-\name) at (\layersep,-\y *\vertsepfactor cm) {};

    \foreach \name / \y in {1,...,\nhid}
        \path[yshift=0.0cm]
            node[hidden2 neuron] (H2-\name) at (2*\layersep,-\y *\vertsepfactor cm) {};
            
          % Draw the 3rd hidden layer nodes
    \foreach \name / \y in {1,...,\nhid}
        \path[yshift=0.0cm]
            node[hidden3 neuron] (H3-\name) at (3*\layersep,-\y *\vertsepfactor cm) {};
            
  %\node[output neuron,pin={[pin edge={->}]right:Output}, right of=H-3] (O) {};

    \foreach \name / \y in {1,...,\nop}
        \path[yshift=-1cm]
            node[output neuron] (O-\name) at (4* \layersep,-\y* \vertsepfactor cm) {};
            
  % Connect every node in the input layer with every node in the
  % hidden layer.
    \foreach \source in {1,...,\nip}
        \foreach \dest in {1,...,\nhid}
            \path (I-\source) edge (H-\dest);

  % Connect every node in the hidden layer with the hidden2 layer
    \foreach \source in {1,...,\nhid}
      \foreach \dest in {1,...,\nhid}
                  \path (H-\source) edge (H2-\dest);

    \foreach \source in {1,...,\nhid}
      \foreach \dest in {1,...,\nhid}
                  \path (H2-\source) edge (H3-\dest);
                  
    \foreach \source in {1,...,\nhid}
      \foreach \dest in {1,...,\nop}
                  \path (H3-\source) edge (O-\dest);
                  
  % Annotate the layers
    \node[annot,above of=H-1, node distance=1cm] (hl) {Hidden layer 1};
    \node[annot,right of=hl] {Hidden layer 2};
     \node[annot,left of=hl] {Input layer};
     \node[annot,above of=H3-1, node distance=1cm] (hl) {Hidden layer 3};

    \node[annot,above of=O-1, node distance=1cm] (hl) {Output layer};

  % arrows from op to h
  %\draw [->,black,dashed,ultra thick] (O.south) to [out=-90,in=-30]  (H-2.south east);
    
  %(H-1) edge[bend left] node [right] {asdf} (0);
  %\draw [->,red] (H-1.north) to [out=150,in=30] (O.north);
  %\draw [->,red] (H-1.north) to [out=50,in=50]  (O.north);

\end{tikzpicture}
%\caption{A deep network with three hidden layers.  }
\label{deepnetwork32}
\end{center}
\end{figure}% neuralnetimage.tex
A deep network with three hidden layers.  

This embodies the {\em credit assignment} or {\em blame assignment} problem.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Simplest Neural Network: Definitions}
 %  \framesubtitle{Taxonomy}
%{\bf Lecture Titles}
\begin{figure}[b] 
\begin{center}
\def\layersep{1.5cm}
\def\nip{1}
\def\nhid{2}
\def\nop{1}
\begin{tikzpicture}[shorten >=1pt,->,draw=black!100, node distance=\layersep, thick]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]

    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=20pt,inner sep=0pt,ball color=gray!20]
    \tikzstyle{input neuron}=[neuron, fill= black!50];
  % \tikzstyle{input neuron}= \shade[ ultra thick,ball color=gray!20]%(2*1.6+1,3)%circle (6) 

    \tikzstyle{output neuron}=[neuron, fill=black!50];
    \tikzstyle{hidden neuron}=[neuron, fill= black!50];
    \tikzstyle{annot} = [text width=4em, text centered]

  % Draw the input layer nodes
    \foreach \name / \y in {1,...,\nip}
  % This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
      %\node[input neuron, pin=left:Input \#\y] (I-\name) at (0,-\y) {};
        \node[input neuron, pin=left: $x$] (I-\name) at (0,-\y) {};

  % Draw the output layer node
    \node[output neuron,pin={[pin edge={->, thick}]right: $y$}, right of=I-2] at  (\layersep,-1) (O) {};
  %\node[output neuron,pin={[pin edge={->}]right:Output}, right of=H-3] (O) {};

  % Connect every node in the input layer with every node in the
  % hidden layer.
    \foreach \source in {1,...,\nip}
     % \foreach \dest in {1,...,\nhid}
            \path (I-\source) edge (O);

        \path (I-1) edge node[above] {$w$} (O);

  % Annotate the layers
  %\node[annot,above of=H-1, node distance=1cm] (hl) {Hidden layer};
    \node[annot, above of=I-1] {Input layer};
    \node[annot, above of=O] {Output layer};
\end{tikzpicture}
%\caption{
%%The simplest possible 
%A neural network with two layers, each containing  one artificial neuron or {\em unit}.
%The  {\em state} $x$ of the unit in the input layer affects the state $y$ of the unit in the output layer via a connection weight $w$.
% }
\label{figANN11}
\end{center}
\end{figure}

Definitions
\begin{description}
\item[ ] $x$ {\em state} of input unit
\item[] $w$ {\em weight} connecting two units
\item[] $u$ total {\em input} to a unit (e.g. to output unit)
\item[] $y$ state of output unit
\item[] $y=f(u)$ the {\em activation function} of a unit is $f$
\item[] $\ytarg$ desired or {\em target value} of output unit
\end{description}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Simplest Neural Network: From input to output}
 %  \framesubtitle{Taxonomy}
%{\bf Lecture Titles}
\begin{figure}[b] 
\begin{center}
\def\layersep{1.5cm}
\def\nip{1}
\def\nhid{2}
\def\nop{1}
\begin{tikzpicture}[shorten >=1pt,->,draw=black!100, node distance=\layersep, thick]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]

    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=20pt,inner sep=0pt,ball color=gray!20]
    \tikzstyle{input neuron}=[neuron, fill= black!50];
  % \tikzstyle{input neuron}= \shade[ ultra thick,ball color=gray!20]%(2*1.6+1,3)%circle (6) 

    \tikzstyle{output neuron}=[neuron, fill=black!50];
    \tikzstyle{hidden neuron}=[neuron, fill= black!50];
    \tikzstyle{annot} = [text width=4em, text centered]

  % Draw the input layer nodes
    \foreach \name / \y in {1,...,\nip}
  % This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
      %\node[input neuron, pin=left:Input \#\y] (I-\name) at (0,-\y) {};
        \node[input neuron, pin=left: $x$] (I-\name) at (0,-\y) {};

  % Draw the output layer node
    \node[output neuron,pin={[pin edge={->, thick}]right: $y$}, right of=I-2] at  (\layersep,-1) (O) {};
  %\node[output neuron,pin={[pin edge={->}]right:Output}, right of=H-3] (O) {};

  % Connect every node in the input layer with every node in the
  % hidden layer.
    \foreach \source in {1,...,\nip}
     % \foreach \dest in {1,...,\nhid}
            \path (I-\source) edge (O);

        \path (I-1) edge node[above] {$w$} (O);

  % Annotate the layers
  %\node[annot,above of=H-1, node distance=1cm] (hl) {Hidden layer};
    \node[annot, above of=I-1] {Input layer};
    \node[annot, above of=O] {Output layer};
\end{tikzpicture}
%\caption{
%%The simplest possible 
%A neural network with two layers, each containing  one artificial neuron or {\em unit}.
%The  {\em state} $x$ of the unit in the input layer affects the state $y$ of the unit in the output layer via a connection weight $w$.
% }
\label{figANN11}
\end{center}
\end{figure}

If the input state is $x$ and if the weight of the connection from the input unit to the output unit is $w$, then the total input $\yip$ to the output unit is
\bea
	\yip & = & w  x. \label{eqsimplestip}
\eea
%We will omit the multiplication sign from now on, and write simply $\yip = w  x$.
In general, the state  $y$ of a unit is governed by an  {\em activation function} (i.e.\ input/output function) 
\bea
	y & = & \g(\yip).
\eea
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Simplest Neural Network: The Delta Term}
Suppose we wish the  network to learn to associate an input value of $x=0.8$ with a target state of $\ytarg=0.2$. Usually, we have no idea of the correct value for the weight $w$, so we may as well begin by choosing its value at random. Suppose we choose a value $w=0.4$, so the  output state is $y=0.4 \times 0.8 = 0.32$. 

The difference between the output $y$ and the target value $\ytarg$ is defined here as the {\em delta term}:
\bea
	\delta  \jequals y -\ytarg \jequals   0.32-0.2  \jequals  0.12.
\eea
Ideally, we would like to adjust the weight $w$ so that $\delta=0$.  
A standard measure of the error in $y$ is half the squared difference:
\bea
	E%& = & 1/2 \, \delta^{2} \\
	& = & \tfrac{1}{2} \, (wx-\ytarg)^{2} \label{eqE2} \\
			& = &  \tfrac{1}{2} \, (y-\ytarg)^{2} \\
			& = & \tfrac{1}{2} \, \delta^{2}.
\eea

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Simplest Neural Network}
\begin{figure}[b] 
\begin{center} 
{\includegraphics[ width =0.6\textwidth, angle=0 ] {\figurepath/perceptronWith1wt_v3.pdf}}
\label{figgradascent1}
\end{center}
\end{figure}
The optimal weight is  $w^{*}=0.25$. 

The gradient of the error function $E$ at a point $w$ is approximated by ${\Delta E} / {\Delta w}$.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Simplest Neural Network}
   \begin{figure}[b] 
\begin{center} 
{\includegraphics[ width =0.4\textwidth, angle=0 ] {\figurepath/perceptronWith1wt_v3.pdf}}
\label{figgradascent1}
\end{center}
\end{figure}
Given that 
\bea
	E & = & \tfrac{1}{2} \, (wx-\ytarg)^{2} \label{eqE2},
\eea
the gradient of the error function at a point $w$ is approximated by
${\Delta E} / {\Delta w}$. An exact measure of the gradient is defined by the derivative of $E$
(Equation \ref{eqE2}) with respect to $w$:
\bea
	\frac{d E}{dw}  & = & (wx-\ytarg) \, x \label{eqgrad1w}  \approx 	\frac{\Delta E} {\Delta w}.
\eea
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Simplest Neural Network}
   \begin{figure}[b] 
\begin{center} 
{\includegraphics[ width =0.4\textwidth, angle=0 ] {\figurepath/perceptronWith1wt_v3.pdf}}
\label{figgradascent1}
\end{center}
\end{figure}
It will prove useful to write Equation \ref{eqgrad1w} in terms of the {delta term}: 
\bea
	\frac{d E}{dw} = \delta \, x. \label{eqgrad1wA}
\eea
The {\em magnitude} of the gradient indicates the steepness of the slope at $w$,
and the {\em sign} of the gradient indicates the direction that increases $E$.
% a positive gradient (like that shown in Figure~\ref{figgradascent1} at $w=0.4$) means that increasing $w$ increases $E$, %, and vice versa.  so to decrease $E$ we should decrease the value of $w$. 
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Simplest Neural Network}
    \begin{figure}[b] 
\begin{center} 
{\includegraphics[ width =0.3\textwidth, angle=0 ] {\figurepath/perceptronWith1wt_v3.pdf}}
\label{figgradascent1}
\end{center}
\end{figure}
{The direction of the gradient measured using calculus points uphill}, and is called the {\em direction of steepest ascent}.   This means that in order to reduce $E$,  we should change the value of $w$ by a small amount $\Delta w$ in the {\em direction of steepest descent}: % Accordingly, the change in the weight should be
\bea
	\Delta w & = &  -\epsilon \, \frac{dE}{dw}\\[5pt]
		 & = &  -\epsilon  \, \delta \, x, \label{eqgrad1wAJ}
\eea% p104 Herz, p97 Bishop
where the size of the step is defined by a {\em learning rate parameter} $\epsilon$.  
%Equation \ref{eqgrad1wAJ} is known as the {\em delta rule}, the {\em Widrow--Hoff rule}, or the {\em least mean square} (LMS) rule. 
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{The Simplest Neural Network: Algorithm}
\begin{figure}[b!]
\begin{BoxExplainer}[1.0\textwidth]%[\keypointwidth\textwidth]
\begin{algorithm}[H]
 \SetKwInOut{Output}{output}
 {\bf Gradient Descent}\\% for Figure \ref{figANN11}:}\\ 
 \textbf{Learning One Association}\\
  	% Learning one association\\
 	initialise network weight $w$ to random value 	\\
	%learn mapping from input $x$ to target output $\ytarg$\\
	set input unit states $x$ to training vector $x$ \\
	set learning to true\\
 	\While {learning}
 		{
		get state of output unit $y = w  x$ \\ 
		get delta term $\delta = y -\ytarg$ \\
		get weight gradient for input vector   $dE/dw = \delta x$ \\
		get change in weight  $\Delta w  = -\epsilon\, dE/dw$\\
		update weight $w \leftarrow w + \Delta w$\\
		 \If  {gradient $dE/dw \approx 0$} 
		 		{set learning to false}
 		}
	%\Output{weight $w$}
	  %\caption{Gradient Descent for a Network With Two Weights}
\end{algorithm}
\end{BoxExplainer}%\end{center}
 \label{boxLMM}
\end{figure}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Gradient Descent for a Network with Two Input Units}
\begin{figure}[b!] 
\begin{center}
\def\layersep{1.5cm}
\def\nip{2}
\def\nhid{2}
\def\nop{1}
\begin{tikzpicture}[shorten >=1pt,->,draw=black!100, node distance=\layersep, thick]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]

    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=20pt,inner sep=0pt,ball color=gray!20]
    \tikzstyle{input neuron}=[neuron, fill= black!50];
    \tikzstyle{output neuron}=[neuron, fill=black!50];
    \tikzstyle{hidden neuron}=[neuron, fill= black!50];
    \tikzstyle{annot} = [text width=4em, text centered]

  % Draw the input layer nodes
    \foreach \name / \y in {1,...,\nip}
  % This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
      %\node[input neuron, pin=left:Input \#\y] (I-\name) at (0,-\y) {};
        \node[input neuron, pin=left: $x_{\y}$] (I-\name) at (0,-\y) {};

  % Draw the output layer node
    \node[output neuron,pin={[pin edge={->, thick}]right: $y$}, right of=I-2] at  (\layersep,-1.5 cm) (O) {};
  %\node[output neuron,pin={[pin edge={->}]right:Output}, right of=H-3] (O) {};

  % Connect every node in the input layer with every node in the
  % hidden layer.
    \foreach \source in {1,...,\nip}
     % \foreach \dest in {1,...,\nhid}
            \path (I-\source) edge (O);

        \path (I-1) edge node[above] {$w_{1}$} (O);
        \path (I-2) edge node[below] {$w_{2}$} (O);

  % Annotate the layers
  %\node[annot,above of=H-1, node distance=1cm] (hl) {Hidden layer};
    \node[annot, above of=I-1] {Input layer};
    \node[annot, above of=O] {Output layer};
\end{tikzpicture}
\caption{
A neural network with two input units and one output unit.
}
\label{NETsolution21}
\end{center}
\end{figure}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Gradient Descent for a Network with Two Input Units}
%To make things a bit more realistic, consider a neural network with two input units and one output unit, as shown in Figure \ref{NETsolution21}.  
This network can learn up to two associations.  
 Each association consists of an input, which is a pair of values $x_{1}$ and $x_{2}$, and each corresponding output is a single value $y$. 
%In this network, there are two connection weights $w_{1}$ and $w_{2}$. %At this stage, readers who are not familiar with vector-matrix notation are advised to read the vector-matrix tutorial in Appendex \ref{vecmattut}.

Given one input $(x_{1}, x_{2})$, the output $y$ is found by multiplying each input value by its corresponding weight and then summing the resultant products: 
\bea
	y & = & w_{1} x_{1} + w_{2} x_{2}. \label{eqinnerprodlong}
\eea
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Gradient Descent for a Network with Two Input Units}
This can be written succinctly if we represent the weights as a vector, written in bold typeface:% depicted in Figure \ref{figweightvec1} 
\bea
	\bw & = & (w_{1},w_{2}).
\eea
Similarly, each pair of input values can be represented as a vector, again in bold typeface:
\bea
	\bx & = & (x_{1},x_{2}).
\eea
The  \joutput $y$ for an input $\bx$ is found from the {\em dot} or {\em inner} product,
\bea
	y & = & \bw \cdot \bx,
\eea
which is defined by Equation \ref{eqinnerprodlong}. %This is also called the  {\em inner} product. 

Notice that scalar variables are  in italics, whereas vectors are in bold typeface. 


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Gradient Descent for a Network with Two Input Units}
%As stated above, this  network can learn two associations.
We use subscripts  
%(\eg $\bx_{1}$ and $\bx_{2}$)
 to denote each association 
 %between an input vector $\bx_{1}$  and the corresponding state   $y_{1}$ of the output unit, and between an input vector $\bx_{2}$ and the state  $y_{2}$ of the output unit, such that 
\bea
\begin{split}\label{eq2assoc}
	y_{1} & = & \bw \cdot  \bx_{1}, \\
	y_{2} & = & \bw  \cdot \bx_{2}. 
\end{split}
\eea
%The vector notation is succinct, but it can also hide the apparent complexity of the problem. So just this once, 
We will write the problem out in full
%This requires using additional subscripts to represent each input vector, so that $\bx_{1}=( x_{11}, x_{21})$ and $\bx_{2}=( x_{12}, x_{22})$, and then the two Equations \ref{eq2assoc} become 
\bea
\begin{split}\label{eq2assocfull}
    y_{1} & = & w_{1} x_{11} + w_{2} x_{21}, \\
	y_{2} & = &  w_{1} x_{12} + w_{2} x_{22}. 
\end{split}
\eea
We can recognise this as two simultaneous equations with two unknowns ($w_{1}$ and $w_{2}$), so we know that a solution for $w_{1}$ and $w_{2}$ usually exists. 

We could find this solution manually, but because we know that the problems we encounter later will become unrealistic for manual methods, we will stick to using gradient descent. 
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%  \frametitle{Gradient Descent for a Network with Two Input Units}
%\bea
%\begin{split}\label{eq2assocfull}
%    y_{1} & = & w_{1} x_{11} + w_{2} x_{21}, \\
%	y_{2} & = &  w_{1} x_{12} + w_{2} x_{22}. 
%\end{split}
%\eea
%At this point, we can recognise the problem as two simultaneous equations with two unknowns ($w_{1}$ and $w_{2}$), so we know that a solution for $w_{1}$ and $w_{2}$ usually exists. 
%We could find this solution manually, but because we know that the problems we encounter later will become unrealistic for manual methods, we will stick to using gradient descent. 
%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Gradient Descent for a Network with Two Input Units}
To use gradient descent, we first need to write down an error function like Equation \ref{eqE2}. 
%, but for two associations. 
The error function for the first association is
\bea
	E_{1} & = & \tfrac{1}{2} \, (\bw \cdot \bx_{1}-\ytarg_{1})^{2}, \label{eqE1a}
\eea
and for the second association it is
\bea
	E_{2} & = & \tfrac{1}{2} \, (\bw \cdot \bx_{2} -\ytarg_{2})^{2}. \label{eqE2a}
\eea
The error function for the set of two associations is the sum
\bea
	E  & = & E_{1}+E_{2}\\ 
		& = & \tfrac{1}{2} \, [ (\bw \cdot \bx_{1} -\ytarg_{1})^{2} + (\bw \cdot \bx_{2} -\ytarg_{2} )^{2}], \label{eqE3a}
	%& = & 1/2 \, \sum (y_{t} - \ytarg_{t})^{2},
\eea
which can be written  succinctly using the summation convention as
\bea
	E & = & \frac{1}{2} \sum_{t=1}^{2} (\bw \cdot \bx_{t} -\ytarg_{t} )^{2}. \label{eqE}
\eea

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Gradient Descent for a Network with Two Input Units}
\begin{figure}[b] 
\begin{center} 
{\includegraphics[ width =0.5\textwidth, angle=0 ] {\figurepath/figgraddesc3Dc}}
\caption{
The error surface is obtained by evaluating  Equation \ref{eqE} over a range of values for $w_{1}$ and $w_{2}$. 
Given an initial weight vector $\bw=(-0.8,-1.6)$, the direction of steepest descent is $-\nabla_{\bw} E$ (shown by an arrow on the ground plane). 
The white dots depict the evolution of weights during learning using Equation \ref{eqdeltasimple}.
 }
\label{figgradascent2}
\end{center}
\end{figure}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand{\d}{\partial}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Gradient Descent for a Network with Two Input Units}
Using the {\em chain rule}, the gradient of the error function with respect to $w_{1}$ for the $t$th association ($t = 1$ or 2) is
\index{chain rule}%
\bea
	\frac{\partial E_{t}}{\d w_{1}} 	& = & \frac{\@ E_{t}}{\@ y_{t}}  \frac{\d y_{t}}{\d w_{1}},  \label{eqgrad1w1a}
\eea
where   ${\@ E_{t}} / {\@ y_{t}} = (\bw \cdot \bx_{t}-\ytarg_{t})$,  
$y_{t}=\bw \cdot \bx_{t}$, and 
 ${\d y_{t}} / {\d w_{1}}=x_{1t}$, 
so 
\bea
	\frac{\partial E_{t}}{\d w_{1}} 	%& = & \frac{\@ E_{t}}{\@ y_{t}}  \frac{\d y_{t}}{\d w_{1}}  \\
							& = &  (\bw \cdot \bx_{t}-\ytarg_{t}) \, x_{1t}. \label{eqgrad1w1b}
							%& = &  (\bw \cdot \bx_{t}-\ytarg_{t}), \label{eqgrad1w1aERROR}
\eea
Given that the delta term for the $t$th association is
\bea
	\delta_{t} & = &  (\bw \cdot \bx_{t}-\ytarg_{t}), \label{eqgrad1w1aERROR}
\eea
we then have
\bea
	\frac{\partial E_{t}}{\d w_{1}} & = & \delta_{t} \, x_{1t}. \label{eqgrad1w1aERRORA}
\eea

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Gradient Descent for a Network with Two Input Units}
When considered over both associations, the gradient of the error function with respect to $w_{1}$ is
\bea
	\frac{\partial E}{\d w_{1}} & = & \sum_{t=1}^{2} \delta_{t}  \, x_{1t}. \label{eqgrad1w1}
\eea
Similarly, the gradient with respect to $w_{2}$ is
\bea
	\frac{\d E}{\d w_{2}} & = & \sum_{t=1}^{2} \delta_{t}  \, x_{2t}. \label{eqgrad1w2}
\eea
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Gradient Descent for a Network with Two Input Units}
 The  direction of steepest ascent is a vector on the ground plane that points in the direction to go in order to increase the value of $E$ as quickly as possible. 
This direction is represented by % ${dE}/{d\bw}$ or by
 the {\em nabla\/} symbol  ($\nabla$), 
which is a vector of scalar gradients: 
\bea
	%\vspace{0.1in}
	%\nn \\ 
			 	\nabla_{\bw} E & = &  	\left( \frac{\d E}{\d w_{1}} , \:\frac{\d E}{\d w_{2}} \right), \label{eqgradE}
\eea
where the subscript $\bw$ indicates a derivative with respect to $\bw$. %; this subscript will be omitted below. 

If the direction of steepest ascent is $\nabla E$ then the direction of steepest descent is $-\nabla E$,
 as shown in Figure \ref{figgradascent2}. Accordingly, if the current value of the weight vector is $\bw_{\rm old}$, then
\bea
	\bw_{\rm new} & = & \bw_{\rm old}    -\epsilon \, \nabla E.  \label{eqdeltasimple}
\eea 
%Learning is achieved by repeated application of Equation \ref{eqdeltasimple},  as depicted in Figure \ref{figgradascent2}. Near the optimal weight vector $\bw^{*}$, the magnitude of the gradient $| \nabla E | = ( ( \d E/ \d w_{1})^{2} + (\d E/ \d w_{2})^{2})^{1/2}$ is approximately zero (where $|\cdot|$ denotes vector length).

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Gradient Descent for a Network with Two Input Units}
\begin{figure}[b!]
\begin{BoxExplainer}[1.0\textwidth]%[\keypointwidth\textwidth]
\begin{algorithm}[H]
 \SetKwInOut{Output}{ouput}
% {\bf Gradient Descent for a Network With Two Weights} \\%\\Learning Two Associations}} 
 	initialise  weights $\bw$ to random values; set learning to true\\
 	\While {learning}
 		{
		set recorder of weight change vectors $\Delta \bw$ to zero\\
		\ForEach{association from $t=1$ to $2$} 
			{
			set input unit states $\bx$ to $t$th training vector $\bx_{t}$ \\
			get state of output unit $y_{t} = \bw \cdot \bx_{t}$ \\ 
			get delta term $\delta_{t} = y_{t}-\ytarg_{t}$ \\
			get weight gradient for $t$th input vector $\nabla E_{t} = \delta_{t} \bx_{t}$ \\
			get change in weights for $t$th input vector $\Delta \bw_{t}$=$-\epsilon \nabla E_{t}$\\
			accumulate weight changes in $\Delta \bw \leftarrow \Delta \bw + \Delta \bw_{t}$
			}
			update weights $\bw \leftarrow \bw + \Delta \bw$\\
			 \If  {gradient $|\nabla E |\approx 0$} 
			 		{set learning to false}
 		}
	%\Output{weights $\bw$}
	  %\caption{Gradient Descent for a Network With Two Weights}
\end{algorithm}
\end{BoxExplainer}%\end{center}
 \label{boxLMM2}
\end{figure}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{A Network with Four Input and Output Units}
\begin{figure}[b!] 
\begin{center}
\def\layersep{2.0cm}
\def\vertsepfactor{0.8}
\def\nip{4}
\def\nhid{4}
\def\nop{4}
\subfloat[]{
\begin{tikzpicture}[shorten >=1pt,->,draw=black!100, node distance=\layersep, thin]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]

    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=20pt,inner sep=0pt,ball color=gray!20]
    \tikzstyle{input neuron}=[neuron, fill= black!50];
    \tikzstyle{output neuron}=[neuron, fill=black!50];
    \tikzstyle{hidden neuron}=[neuron, fill= black!50];
        \tikzstyle{hidden2 neuron}=[neuron, fill= black!50];
        \tikzstyle{hidden3 neuron}=[neuron, fill= black!50];

    \tikzstyle{annot} = [text width=4em, text centered]

  % Draw the input layer nodes
    \foreach \name / \y in {1,...,\nip}
      % Skip labels
        \node[input neuron] (I-\name) at (0,-\y* \vertsepfactor) {};
            
    \foreach \name / \y in {1,...,\nop}
        \path[yshift=0cm]
            node[output neuron] (O-\name) at (1* \layersep,-\y* \vertsepfactor cm) {};
            
  % Connect every node in the input layer with every node in the
  % hidden layer.
    \foreach \source in {1,...,\nip}
        \foreach \dest in {1,...,\nhid}
            \path (I-\source) edge (O-\dest);

    \node[annot,above of=I-1, node distance=1cm] (I-l) {Input layer};

    \node[annot,above of=O-1, node distance=1cm] (O-l) {Output layer};

\end{tikzpicture}
}
\def\layersep{2.0cm}
\def\vertsepfactor{0.8}
\def\nip{4}
\def\nhid{4}
\def\nop{1}
\subfloat[]{
\begin{tikzpicture}[shorten >=1pt,->,draw=black!100, node distance=\layersep, thin]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]

    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=20pt,inner sep=0pt,ball color=gray!20]
    \tikzstyle{input neuron}=[neuron, fill= black!50];
    \tikzstyle{output neuron}=[neuron, fill=black!50];
    \tikzstyle{hidden neuron}=[neuron, fill= black!50];
        \tikzstyle{hidden2 neuron}=[neuron, fill= black!50];
        \tikzstyle{hidden3 neuron}=[neuron, fill= black!50];

    \tikzstyle{annot} = [text width=4em, text centered]

  % Draw the input layer nodes
    \foreach \name / \y in {1,...,\nip}
      % Skip labels
        \node[input neuron] (I-\name) at (0,-\y* \vertsepfactor) {};
            
    \foreach \name / \y in {1,...,\nop}
        \path[yshift=0cm]
            node[output neuron] (O-\name) at (1* \layersep,-\y* \vertsepfactor cm) {};
            
  % Connect every node in the input layer with every node in the
  % hidden layer.
    \foreach \source in {1,...,\nip}
        \foreach \dest in {1,...,\nop}
            \path (I-\source) edge (O-\dest);

    \node[annot,above of=I-1, node distance=1cm] (I-l) {Input layer};

    \node[annot,above of=O-1, node distance=1cm] (O-l) {Output layer};

\end{tikzpicture}
}
\caption{
(a) A neural network with four input units and four output units (i.e.\ a 4-4 network) can be viewed as four neural networks like the one in (b), where each of the four neural networks has the same  four input units but a different output unit (i.e.\ four 4-1 networks). 
}
\label{etwork32876}
\end{center}
\end{figure}% neuralnetimage.tex
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{Learning Photographs}
 \newcommand{\tpw}{0.14}
 \newcommand{\tpwgap}{0.01in}
\begin{figure}[b]%%msc_demo_sebtel1  main_bpcg_3.m
\begin{center}
\subfloat[]{ \includegraphics[width= \tpw \textwidth] {\figurepath/figteleriorig} }
\hspace{\tpwgap}
\subfloat[]{ \includegraphics[width= \tpw \textwidth] {\figurepath/figteleriip} }
\hspace{\tpwgap}
\subfloat[]{ \includegraphics[width= \tpw \textwidth] {\figurepath/figteleriop} }
\subfloat[]{ \includegraphics[width= \tpw \textwidth] {\figurepath/figseborig} }
\hspace{\tpwgap}
\subfloat[]{ \includegraphics[width= \tpw \textwidth] {\figurepath/figsebip} }
\hspace{\tpwgap}
\subfloat[]{ \includegraphics[width= \tpw \textwidth] {\figurepath/figsebop} }
\end{center}
\end{figure}
Learning photographs using a network with the same type of architecture as in Figure \ref{etwork32876}a. 
Each photograph $\bx_{t}$ consists of $50 \times 50$ pixels. 
A linear network was used, with an array of $50 \times 50$ input units and an array of $50 \times 50$ output units.
The network was trained to associate each of two training vectors (a and d) with itself.
%, so that the input (a) yielded an output very similar to (a). 

For example, adding noise to (a) yielded (b), and when (b) was used as input to the network, the output was (c), showing that the network's memory is {\em content addressable}.  
%Similarly, adding noise to (d) yielded (e), and when (e) was used as input to the network, the output was (f). 
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%   \frametitle{asd }
%\begin{figure}[b!] 
%\begin{center}
%\def\layersep{2.5cm}
%\def\nip{2}
%\def\nhid{2}
%\def\nop{1}
%\begin{tikzpicture}[shorten >=1pt,->,draw=black!100, node distance=\layersep, thick]
%    \tikzstyle{every pin edge}=[<-,shorten <=1pt]
%
%    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=20pt,inner sep=0pt,ball color=gray!20]
%    \tikzstyle{input neuron}=[neuron, fill= black!50];
%    \tikzstyle{output neuron}=[neuron, fill=black!50];
%    \tikzstyle{hidden neuron}=[neuron, fill= black!50];
%    \tikzstyle{annot} = [text width=4em, text centered]
%
%  % Draw the input layer nodes
%    \foreach \name / \y in {1,...,\nip}
%        \node[input neuron] (I-\name) at (0,-\y) {$\ipstate_{\y t}$};
%
%  % Draw the hidden layer nodes
%    \foreach \name / \y in {1,...,\nhid}
%        \path[yshift=0.0cm]
%            node[hidden neuron] (H-\name) at (\layersep,-\y cm) {$\hstate_{ \y t}$};
%
%  % Draw the output layer node
%%    \node[output neuron,pin={[pin edge={->, thick}]right: $y_{t}$}, right of=H-2] at  (\layersep,-1.5 cm) (O) {$\opstate_{t}$};
%    \node[output neuron, right of=H-2] at  (\layersep,-1.5 cm) (O) {$\opstate_{t}$};
%
%  % Connect every node in the input layer with every node in the
%  % hidden layer.
%    \foreach \source in {1,...,\nip}
%        \foreach \dest in {1,...,\nhid}
%            \path (I-\source) edge (H-\dest);
%            
%            \path (I-1) edge node[above] {$w_{ij}$} (H-1);
%
%  % Connect every node in the hidden layer with the output layer
%    \foreach \source in {1,...,\nhid}
%        \path (H-\source) edge  (O) ;
%
%        \path (H-1) edge node[above] {$w_{jk}$} (O);
%
%  % Annotate the layers
%    \node[annot,above of=H-1, node distance=1cm] (hl) {Hidden layer};
%    \node[annot,left of=hl] {Input layer};
%    \node[annot,right of=hl] {Output layer};
%    
%     \path[yshift=-1.95cm]
%     node[output neuron] (Bias-2) at (0 cm,-1.2 cm) {-1};%{$\delta_{\name}$};
%     
%        \foreach \dest in {1,...,\nhid}
%            	{		
%            		\path (Bias-2) edge  [dashed,thin] (H-\dest);
%		}
%	
%	\node[annot,below of= Bias-2, node distance=0.6cm] (hl) {Bias unit};
%	    
%	%        \path[yshift=-1.95cm]
%         \node[output neuron] (Bias-3) at (2.5 cm,-3.2 cm) {-1};%{$\delta_{\name}$};
%         \path (Bias-3) edge [dashed, thin] (O);
%	\node[annot,below of= Bias-3, node distance=0.6cm] (hl) {Bias unit};
%\end{tikzpicture}
%\end{center}
%\end{figure}
%A 2-2-1 network showing how bias weights can be implemented by adding a bias unit that connects to the hidden and output layers with a fixed state of $-1$. 
%%Unit states are indexed by layer ($\ipstate=\:$input, $\hop=\:$hidden, $\yop=\:$output) and by association number~$t$.  
%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{A Backprop Neural Network}
   \begin{figure}[b!] 
\begin{center}
\def\layersep{2.5cm}
\def\nip{2}
\def\nhid{2}
\def\nop{1}
\begin{tikzpicture}[shorten >=1pt,->,draw=black!100, node distance=\layersep, thick]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]

    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=20pt,inner sep=0pt,ball color=gray!20]
    \tikzstyle{input neuron}=[neuron, fill= black!50];
    \tikzstyle{output neuron}=[neuron, fill=black!50];
    \tikzstyle{hidden neuron}=[neuron, fill= black!50];
    \tikzstyle{annot} = [text width=4em, text centered]

  % Draw the input layer nodes
    \foreach \name / \y in {1,...,\nip}
        \node[input neuron] (I-\name) at (0,-\y) {$\ipstate_{\y t}$};

  % Draw the hidden layer nodes
    \foreach \name / \y in {1,...,\nhid}
        \path[yshift=0.0cm]
            node[hidden neuron] (H-\name) at (\layersep,-\y cm) {$z_{ \y t}$};

  % Draw the output layer node
%    \node[output neuron,pin={[pin edge={->, thick}]right: $y_{t}$}, right of=H-2] at  (\layersep,-1.5 cm) (O) {$\opstate_{t}$};
    \node[output neuron, right of=H-2] at  (\layersep,-1.5 cm) (O) {$\opstate_{t}$};

  % Connect every node in the input layer with every node in the
  % hidden layer.
    \foreach \source in {1,...,\nip}
        \foreach \dest in {1,...,\nhid}
            \path (I-\source) edge (H-\dest);
            
            \path (I-1) edge node[above] {$w_{ij}$} (H-1);

  % Connect every node in the hidden layer with the output layer
    \foreach \source in {1,...,\nhid}
        \path (H-\source) edge  (O) ;

        \path (H-1) edge node[above] {$w_{jk}$} (O);

  % Annotate the layers
    \node[annot,above of=H-1, node distance=1cm] (hl) {Hidden layer, state=$z_{j}$};
    \node[annot,left of=hl] {Input layer, state=$x_{i}$};
    \node[annot,right of=hl] {Output layer, state=$y_{k}$};
    
     %\path[yshift=-1.95cm]
    %node[output neuron] (Bias-2) at (0 cm,-1.2 cm) {-1};%{$\delta_{\name}$};
     
%        \foreach \dest in {1,...,\nhid}
%            	{		
%            	\path (Bias-2) edge  [dashed,thin] (H-\dest);
%		}
	
	%\node[annot,below of= Bias-2, node distance=0.6cm] (hl) {Bias unit};
	    
%         \node[output neuron] (Bias-3) at (2.5 cm,-3.2 cm) {-1};%{$\delta_{\name}$};
   %      \path (Bias-3) edge [dashed, thin] (O);
	%\node[annot,below of= Bias-3, node distance=0.6cm] (hl) {Bias unit};

\end{tikzpicture}
\label{XORsolutionF}
\end{center}
\end{figure}
Unit states are indexed by layer ($\ipstate=\:$input, $z=\:$hidden, $\yop=\:$output) and by association number~$t$.  

A key property of backprop networks is that they can compute nonlinear functions, because most units have nonlinear activation functions.

BUT this also means that the error surface is not convex, so it has {\em local minima}.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{Unit Activation Function}
\begin{figure}[b] 
\begin{center}
{\includegraphics[ width =0.75 \textwidth, angle=0 ] {\figurepath/figsigmoidandderiv2ndprinting.pdf} }% y=1/(1+exp -z ) z=ip.
\label{fig_CellTransferFunc_journalpcbi1001078A}%
\end{center}
\end{figure}
Sigmoidal activation function
% (solid curve, Equation \ref{eqsigmoid01}) and its derivative (dashed curve, Equation \ref{eqerrorhidAFD1}, not drawn to scale). A typical sigmoidal activation function is% the state of the $j$th hidden unit is
\bea
	\yop = \g (\yip ) \label{eqyj3} 
		=  ( 1+e^{-\yip} )^{-1}, \label{eqsigmoid01}
\eea
where $\yip$ is the total input to a unit. The derivative is
\bea
	\frac{ d \yop } { d \yip } &   = &    \yop \:  (1-\yop). \label{eqerrorhidAFD1}
\eea
 %as shown in Figure \ref{fig_CellTransferFunc_journalpcbi1001078A}.  Unlike a step function, a sigmoidal activation function has a finite derivative for all input values. 
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{A Backprop Neural Network}
\begin{figure}[b!] 
\begin{center}
\def\layersep{2.5cm}
\def\nip{2}
\def\nhid{2}
\def\nop{1}
\begin{tikzpicture}[shorten >=1pt,->,draw=black!100, node distance=\layersep, thick]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]

    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=20pt,inner sep=0pt,ball color=gray!20]
    \tikzstyle{input neuron}=[neuron, fill= black!50];
    \tikzstyle{output neuron}=[neuron, fill=black!50];
    \tikzstyle{hidden neuron}=[neuron, fill= black!50];
    \tikzstyle{annot} = [text width=4em, text centered]

  % Draw the input layer nodes
    \foreach \name / \y in {1,...,\nip}
  % This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
      %\node[input neuron, pin=left:Input \#\y] (I-\name) at (0,-\y) {};
        \node[input neuron, pin=left: $x_{\y}$] (I-\name) at (0,-\y) {};

  % Draw the hidden layer nodes
    \foreach \name / \y in {1,...,\nhid}
        \path[yshift=0.0cm]
            node[hidden neuron] (H-\name) at (\layersep,-\y cm) {$\delta_{\name t}$ };

  % Draw the output layer node
    \node[output neuron,pin={[pin edge={->, thick}]right: $y$}, right of=H-2] at  (\layersep,-1.5 cm) (O) {$\delta_{kt}$};
  %\node[output neuron,pin={[pin edge={->}]right:Output}, right of=H-3] (O) {};

  % Connect every node in the input layer with every node in the
  % hidden layer.
    \foreach \source in {1,...,\nip}
        \foreach \dest in {1,...,\nhid}
            \path (I-\source) edge (H-\dest);
            \path (I-1) edge node[above] {$w_{ij}$} (H-1);

  % Connect every node in the hidden layer with the output layer
    \foreach \source in {1,...,\nhid}
        \path (H-\source) edge  (O) ;
            
        \path (H-1) edge node[above] {$w_{jk}$} (O);

  % Annotate the layers
    \node[annot,above of=H-1, node distance=1cm] (hl) {Hidden layer};
    \node[annot,left of=hl] {Input layer};
    \node[annot,right of=hl] {Output layer};
    
  % arrows from op to h
    \draw [->,black,dashed,ultra thick] (O.south west) to [out=-90,in=-30]  (H-1.south east);
    \draw [->,black,dashed,ultra thick] (O.south) to [out=-90,in=-30]  (H-2.south east);

\end{tikzpicture}
\label{XORsolutionB}
\end{center}
\end{figure}
We know how to find the delta term of each output unit.  
%Backward propagation of delta term $\delta_{kt}$ of the output unit through connection weights  in a 2-2-1 network.  
The delta term of the $j$th hidden unit is its derivative times a weighted sum of delta terms in the output layer
\bea
%	    \delta_{jt} & = &     \hstate_{jt}(1-\hstate_{jt}) \sum_{k=1}^{K}  \delta_{kt}\, w_{jk}, \label{eqhiddendelta}
	    \delta_{jt} & = &    \frac{dy_{jt} }{ du_{jt} } \: \sum_{k=1}^{K}  \delta_{kt}\, w_{jk}, \label{eqhiddendelta}
\eea
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{Backprop}
Given the delta term for one association of a unit, the  change in an 'incoming' weight for that association  is 
   \bea
		\Delta w_{ij}(t)   & = & - \Lrate  \delta_{jt} \, \ipstate_{it}. 
\eea
And,   when considered over all $T$ associations, the change in one weight is
\bea
		\Delta w_{ij}   & = & - \Lrate\sum_{t=1}^{T} \delta_{jt} \, \ipstate_{it}. 
\eea
This is a general recipe for updating weights in a backprop network. 
 
Once we have the delta term for each unit then we can adjust all the weights between that unit and all the units in the previous layer. 

%At this point, we have obtained an expression for the weight change applied to every weight in the neural network.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%   \frametitle{Backprop}
%It will prove useful to define the delta term of the $k$th output unit as the first term on the right of Equation~\ref{eqerrorhidAZ}, which is the derivative of $E$ with respect to the input to that unit:
%\bea
%	\delta_{kt} &  = &  \frac{\@ E_{t}}{\@ \yip_{kt}}. \label{eqerrorhidAZQany} 
%			%& = &  (y_{t}-\ytarg_{t}).
%\eea
%Given Equation \ref{eqyj6a}, the second term on the right of Equation \ref{eqerrorhidAZ} is
%\bea
%	\frac{ \@ \yip_{kt}}{\@ w_{jk}} & = & \hstate_{jt},
%\eea
%so we can write  
%Equation \ref{eqerrorhidAZD} as
%\bea
%		\Delta w_{jkt} & = & -\Lrate \: \delta_{kt} \:  \hstate_{jt}.  \label{eqgenbprecipe}
%\eea
%This is a general recipe for updating weights in a backprop network.  
%% The only problem lies in calculating the delta terms of hidden layers. %, which we address next. 
%%Fortunately, 
%Just as the state of each unit in the output layer is calculated by propagating unit states forward from the input layer, so the delta term of each unit in the hidden layer can be calculated by propagating delta values backward from the output layer. 
%%Before seeing this backward propagation in action, 
%To do this, we first need to evaluate the delta term of each output unit. 
%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{The Backprop Algorithm }
   {\small
\begin{figure}[b!]
\begin{BoxExplainer}[1.0\textwidth]%[\keypointwidth\textwidth]
{\bf Backprop (Short Version)} \\ 
\begin{algorithm}[H]
 \SetKwInOut{Output}{ouput}
 	initialise network weights $\bw$ to random values; 
	set learning to true\\
 	\While {learning}
 		{
		set vector of gradients $\nabla E $ to zero\\
		\ForEach{association from $t=1$ to $N$} 
			{
			set input unit states  $\bipstate_{it}$ to $t$th training vector \\
			get state of output units $\by_{kt}$ \\% = \bw \cdot \bx_{t}$ \\ 
			get  delta term $\delta_{kt}$ for each output unit\\
			use output delta terms to get hidden unit  delta terms\\
			use delta terms to get vector of weight gradients $\nabla E_{t}$\\
			accumulate gradient $ \nabla E \leftarrow \nabla E + \nabla E_{t}$\\
			%accumulate weight changes in $\Delta \bw \leftarrow \Delta \bw + \Delta \bw_{t}$\\
			%get weight gradient  wrt $t$th input vector $\nabla E_{t} = \delta_{t} \bx_{t}$ \\
			%get change in weights $t$th input vector $\Delta \bw_{t} = -\epsilon \nabla E_{t}$\\
			}
			get weight change $\Delta \bw = -\Lrate \nabla E $ \\
			update weights $\bw \leftarrow \bw + \Delta \bw$\\
			 \If  { $|  \nabla E | \approx 0$} 
			 		{set learning to false}
 		}
	%\Output{weights $\bw$}
	  %\caption{Gradient Descent for a Network With Two Weights}
\end{algorithm}
\end{BoxExplainer}%\end{center}
 \label{boxBPShort}
\end{figure}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{Global and Local Minima }
\begin{figure}[b] 
\begin{center}
{\includegraphics[ width =0.6 \textwidth, angle=0 ] {\figurepath/figlocalglobalminima1.pdf} }
\caption{Schematic diagram of local and global minima in the error function $E(\bw)$ for  a network with just two weights. 
}
\label{figlocalglobalminima1} 
\end{center}
\end{figure}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{Global and Local Minima }
\begin{figure}[b] 
\begin{center}
{\includegraphics[ width =0.6 \textwidth, angle=0 ] {\figurepath/anneal2BP.pdf} }
\caption{Local and global minima in a cross-section of the error function $E(\bw)$. 
At a given initial weight, $E(\bw)$ may be high, as represented by the black disc.
Gradient-based methods always head downhill, but because they can only move downwards, the final weight often corresponds to a local minimum. 
}
\label{anneal1BP} 
\end{center}
\end{figure}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{Over-fitting, under-fitting, Goldilocks-fitting }
\begin{figure}[b]%
\begin{center}
{ \includegraphics[width=0.99 \textwidth] {\figurepath/figoverfit.jpg} }
%{ \includegraphics[width=0.99 \textwidth] {\figurepath/bishopoverfitt.jpg} }
\label{figoverfit}
\end{center}
\end{figure}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{Preventing Over-fitting with Early Stopping}
\begin{figure}[b]%% earlystopping1.m
\begin{center}
{ \includegraphics[width=0.9 \textwidth] {\figurepath/earlystopping2.pdf} }
\label{earlystopping}
\end{center}
\end{figure}
%Early stopping. 
While learning a {\em training set}, the error on a separate {\em validation set} is monitored to gauge {\em generalisation} performance. 
Training is stopped when the validation error stops decreasing. 
%Generalisation  is measured by performance on the test set.
Other methods include {\em regularisation}.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
   \frametitle{The End}
   Thank you.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\end{document}

\section{Introduction} 
% \subsection{Subsection} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\title{Lecture \thelecnum: Structure}
  \maketitle % article likes titlepage
%  \frametitle{Lecture \thelecnum: Structure}
 %  \framesubtitle{Taxonomy}
  %Part 1
  %\subsection{asdf}
  \begin{itemize}
  % \item Use demo with playing cards to communicate info
 %  \item put up info channel figure early
  \item Introduction 
  \item Nothing in biology ...
  \item Not just how but {\em why}
  \item Pricing neural information
  \item What might work
        \end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{The Problem}
\framesubtitle{}
%%%%%%%%%%%%%%%%%
\begin{figure}[t!] % % make_contrastImages.m
\begin{center}
\includegraphics[width=\textwidth] {\figurepath/figNeuronAsChannelSimple}
\caption{
%
The neuron as a communication channel.
%
}
\label{figNeuronAsChannelSimple}
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{The Problem}
\framesubtitle{}
%%%%%%%%%%%%%%%%%
\begin{figure}[b] % 
\begin{center}
\includegraphics[width=0.3\textwidth] {\figurepath/fig_brainbodyenergybudget}
%
\caption{
%
In a child,  half of the total energy budget  used by the brain.
%
}
\label{figbrainbodyenergybudget}
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{The Problem}
\framesubtitle{}
%%%%%%%%%%%%%%%%%
\begin{figure}[b] % % information_v2.m
\begin{center}
%\includegraphics[width=0.7 \textwidth] {\figurepath/figInfoSpikes.pdf} 
%\subfloat[]
{\includegraphics[width = 0.49 \textwidth] {\figurepath/figInfoINV} }
%\subfloat[]{\includegraphics[width = 0.49 \textwidth] {\figurepath/figInfoStandard} }
%
\caption{In neurons, if we equate axon cross-sectional area with energy then the energy required to send information increases at a supra-linear rate. %(Equation \ref{eqinforatea2}).
%(b) More generally, Shannon's theorems imply that the energy required to increase channel capacity also increases at a supra-linear rate (Equation \ref{eqstandardSN}). In practice, this rate of increase is likely to be larger in neurons.  
}
\label{figInfoSpikes4}
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
 \frametitle{The Answer: Information Theory}
\framesubtitle{}
%%%%%%%%%%%%%%%%%
\begin{figure}[b] % 
\begin{center}
%\includegraphics[ width =0.31 \textwidth, angle=0 ] {\figurepath/Claude_Elwood_Shannon1916_2001.pdf} 
\includegraphics[ width =0.42 \textwidth, angle=0 ] {\figurepath/CES_001ContrastEnhancedJVSsmall.pdf} 
%
\caption{Claude Shannon (1916-2001). }%, father of information theory.}
%\vspace{-15pt}\vspace{-15pt}
\label{Claude_Elwood_Shannon1916_2001}
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%\frametitle{Making Models}
%%\framesubtitle{What Laughlin discovered}
% \end{frame}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\title{Making Models: How vs Why}
  \maketitle 
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{The Input-Output Model Maker}
%\framesubtitle{What Laughlin discovered}
%%%%%%%%%%%%%%%%%
\begin{figure}[bb] % % make_entropycoin1.m
\begin{center}
\includegraphics[ width =0.2 \textwidth, angle=0 ] {\figurepath/figRed_Wine_GlassWiki} 
%
\label{figIRFSTA2} % 
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%
%Two routes for making a model neuron. 
\begin{enumerate}
\item[]  The input-output model maker uses the measured inputs and outputs of a neuron to estimate its {\em impulse response function} (IRF). 
%\item The information model maker uses only the inputs to construct a model which maximises the amount of information that the output provides about the input. 
\end{enumerate}
 \end{frame}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{The Plan: Model Makers}
%\framesubtitle{What Laughlin discovered}
%%%%%%%%%%%%%%%%%
\begin{figure}[bb] % 
\begin{center}
\includegraphics[ width =0.7\textwidth, angle=0 ] {\figurepath/figIRFSTA2} 
%
\label{figIRFSTA2} % 
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%
%Two routes for making a model neuron. 
\begin{enumerate}
\item  The input-output model maker uses the measured inputs and outputs of a neuron to estimate the impulse response function (IRF). 
\item The information model maker uses only the inputs to construct a model which maximises the amount of information (per Joule) that the output provides about the input. 
%\item If these models end up looking the same then this suggests that neurons are the way they are because they maximise the amount of information (per Joule) that the output provides about the input. 
\end{enumerate}
 \end{frame}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Not Just How, But {\em Why}}
%%%%%%%%%%%%%%%%%
\begin{figure}[bb] % 
\begin{center}
\includegraphics[ width =0.6\textwidth, angle=0 ] {\figurepath/figIRFSTA2} 
%
\label{figIRFSTA2} % 
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%
%Two routes for making a model neuron. 
\begin{enumerate}
\item HOW: If the input-output model is a good model then it tells us {\em how} neuronal inputs get transformed into outputs.
\item WHY: If the information model is  a good model then it tells us {\em why}  
neuronal inputs get transformed into outputs in the way that they do.  
\item If these models end up looking the same then this suggests that neurons are the way they are because they maximise the amount of information (per Joule). % that the output provides about the input. 
\end{enumerate}
 \end{frame}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Not Just How, But {\em Why}: The Efficient Coding Hypothesis}

\begin{enumerate}
\item[] {\bf The efficient coding hypothesis} states that the structure of the brain is dominated by the need to transmit information as efficiently as possible (Horace Barlow).
\end{enumerate}
 \end{frame}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Not Just How, But {\em Why}: The Efficient Coding Hypothesis}

\begin{enumerate}
\item[]  Transmitting information as efficiently as possible affects how we (and frogs, horse-shoe crabs) see.
\end{enumerate}
 \end{frame}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%\frametitle{Finding our way, bit by bit}
%\end{frame}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\fi % Lecone

\ifLectwo
\setcounter{lecnum}{2} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Lecture \thelecnum\\Measuring Neural Information1}
\subtitle{} % (optional)
\setcounter{framenumber}{0}
\begin{frame}
  \maketitle % article likes titlepage
  \begin{quote}
{To understand life, one has to understand not just the flow of energy, but also the flow of information.}\\
{\em William Bialek, 2012.} 
%{\em A basic idea in information theory is that information can be treated very much like a physical quantity, such as mass or energy.}\\ Shannon, 1985\cite{shannonlecture1985lct}.
\end{quote}
  \center{MSc in Cognitive and Computational Neuroscience  }
  \center{Department of Psychology}
  \center{JV Stone}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction} 
% \subsection{Subsection} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\title{Lecture \thelecnum: Structure}
  \maketitle % article likes titlepage
%  \frametitle{Lecture \thelecnum: Structure}
 %  \framesubtitle{Taxonomy}
  %Part 1
  %\subsection{asdf}
  \vspace{-1in}
  ADMIN
   \begin{itemize}
  % \item Use demo with playing cards to communicate info
 %  \item put up info channel figure early
   \item Move Wed lecture to 11-1pm?
   \item Email me if you have not received an email from me. j.v.stone@sheffield.ac.uk. 
   \item References for all my PSY6308 lectures are in a google document, which can be reached via my teaching page via here
   \url{http://www.jim-stone.staff.shef.ac.uk/}.\\ Follow links to PSY6308.
%{\small \url{   https://docs.google.com/document/d/1cHcwWgljzq11TAZqqfg244PESISywWxBS_OJqpRbQpM/edit}}
           \end{itemize}
	
   \begin{itemize}
   \item Introduction 
  \item Information Theory: Finding our way, bit by bit
  \item Information in Spike Trains
        \end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\title{Information Theory}
%\title{Finding our way, bit by bit}
  \maketitle 
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Information Theory}
 %\framesubtitle{Laughlin}
  \begin{figure}[b] 
\begin{center}
\begin{tikzpicture}
	[node distance = 0.5cm, auto, >=latex']
	\node [int,ultra thick] (t) [node distance=1.5cm]{Encoder};
	\node (m) [above of=t, node distance = 2cm]{Message};
	\path[->,ultra thick] (m) edge node [right] {$s$}         (t);
	 \node [ultra thick,right of =t,cylinder,draw=black,thick,aspect=0.7,minimum height=3.7cm,minimum width=1.5cm,shape border rotate=180,cylinder uses custom fill, cylinder body fill=gray!30,cylinder end fill=gray!10,node distance = 3.9cm] (zz) {Channel};
	\node [ultra thick] (n) [above of=zz, node distance = 2.1cm] {Noise};
	\node [int,ultra thick] (op) [right of=zz, node distance = 3.5cm] {Decoder};
	\path[->,ultra thick] (n) edge node [right] {$\eta$} (zz);
	\path[->, ultra thick] (t) edge node [above] {$x$} (zz);
	\path[->, ultra thick] (zz) edge node [above] {$y$} (op);
	\node (blank) [ultra thick][above of=op, node distance = 2cm]{Message};
	\path[->, ultra thick] (op) edge node [right] {$s$} (blank);
\end{tikzpicture}
%\caption{The communication channel.  A message (data) is encoded before being used as input to a  communication channel,  which adds noise.    A receiver decodes the channel output to recover the message.    }
\label{figchannel1}
\end{center}
\end{figure}
The communication channel.  A message (data) is encoded before being used as input to a  communication channel, 
which adds noise.   The channel output is decoded to recover the message.  
  \end{frame}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
